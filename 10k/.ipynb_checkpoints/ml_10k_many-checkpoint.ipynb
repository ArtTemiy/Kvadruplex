{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import Sequential\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def read_bed(filename):\n",
    "    return pd.read_csv(filename, sep='\\t', header=None)\n",
    "\n",
    "\n",
    "def to_bed(data, filename):\n",
    "    data.to_csv(filename, sep='\\t', header=None, index=None)\n",
    "\n",
    "N = 100\n",
    "chr_name = 'chr10'\n",
    "histones = ['E003-H3K4me1', 'E003-H3K4me3', 'E003-H3K9me3', 'E003-H3K27me3', 'E003-H3K36me3']\n",
    "h = histones[0]\n",
    "path_to_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (22680, 5, 100)\n",
      "y: (22680,)\n"
     ]
    }
   ],
   "source": [
    "regions_num = np.array([\n",
    "    read_bed('{}/plus_{}_{}.peaks'.format(chr_name, chr_name, h)).shape[0] // 100,\n",
    "    read_bed('{}/plus_{}_{}_random_many.peaks'.format(chr_name, chr_name, h)).shape[0] // 100\n",
    "])\n",
    "\n",
    "\n",
    "X_p = np.zeros((regions_num[0], len(histones), N))\n",
    "X_m = np.zeros((regions_num[1], len(histones), N))\n",
    "for i in range(len(histones)):\n",
    "    h = histones[i]\n",
    "    X_p[:, i, :] = np.array(read_bed('{}/plus_{}_{}.peaks'.format(chr_name, chr_name, h))[3]).reshape(regions_num[0], N)\n",
    "    X_m[:, i, :] = np.array(read_bed('{}/plus_{}_{}_random_many.peaks'.format(chr_name, chr_name, h))[3]).reshape(regions_num[1], N)\n",
    "\n",
    "# X_p = X_p[np.random.choice(X_p.shape[0], X_m.shape[0]), :, :]\n",
    "X = np.concatenate([X_p, X_m])\n",
    "\n",
    "y = np.concatenate(\n",
    "    [\n",
    "        np.ones((X_p.shape[0])),\n",
    "        np.zeros((X_m.shape[0])),\n",
    "    ]\n",
    ")\n",
    "print('X:', X.shape)\n",
    "print('y:', y.shape)\n",
    "\n",
    "classes = 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_cat, y_test_cat = [keras.utils.to_categorical(y, classes) for y in [y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dif = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15876/15876 [==============================] - 6s 348us/step - loss: 0.9505 - acc: 0.7411 1s \n",
      "Epoch 2/10\n",
      "15876/15876 [==============================] - 5s 304us/step - loss: 0.4928 - acc: 0.7560\n",
      "Epoch 3/10\n",
      "15876/15876 [==============================] - 4s 274us/step - loss: 0.4848 - acc: 0.7554 0s - loss: 0.4854 - acc: 0.7\n",
      "Epoch 4/10\n",
      "15876/15876 [==============================] - 4s 276us/step - loss: 0.4743 - acc: 0.7595 1s - lo - ETA: 0s - loss: 0.4768 - \n",
      "Epoch 5/10\n",
      "15876/15876 [==============================] - 4s 278us/step - loss: 0.4752 - acc: 0.7639\n",
      "Epoch 6/10\n",
      "15876/15876 [==============================] - 4s 269us/step - loss: 0.4594 - acc: 0.7626\n",
      "Epoch 7/10\n",
      "15876/15876 [==============================] - 4s 268us/step - loss: 0.4589 - acc: 0.7612 0s - loss: 0.4580 - acc:\n",
      "Epoch 8/10\n",
      "15876/15876 [==============================] - 4s 268us/step - loss: 0.4721 - acc: 0.7607 0s - loss: 0.\n",
      "Epoch 9/10\n",
      "15876/15876 [==============================] - 4s 277us/step - loss: 0.4828 - acc: 0.7620\n",
      "Epoch 10/10\n",
      "15876/15876 [==============================] - 4s 273us/step - loss: 0.4630 - acc: 0.7669\n",
      "0.7989112026560878\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history_dif' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-de74e1c8e8d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mhistory_dif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history_dif' is not defined"
     ]
    }
   ],
   "source": [
    "# diff size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(32, (len(histones), 20), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 10), padding='valid'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(300))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(Dense(180))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=10)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "history_dif.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227471418964358\n",
      "0.3097989949748744\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_train[y_train == 1])\n",
    "print((pred[:, 0] < pred[:, 1]).sum() / pred.shape[0])\n",
    "pred = model.predict(X_train[y_train == 0])\n",
    "print((pred[:, 0] > pred[:, 1]).sum() / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7943/7943 [==============================] - 1s 175us/step - loss: 1.5719 - acc: 0.6029\n",
      "Epoch 2/10\n",
      "7943/7943 [==============================] - 1s 161us/step - loss: 0.5851 - acc: 0.6977\n",
      "Epoch 3/10\n",
      "7943/7943 [==============================] - 2s 284us/step - loss: 0.6639 - acc: 0.6870\n",
      "Epoch 4/10\n",
      "7943/7943 [==============================] - 2s 273us/step - loss: 0.5657 - acc: 0.7125\n",
      "Epoch 5/10\n",
      "7943/7943 [==============================] - 2s 288us/step - loss: 0.5731 - acc: 0.7119\n",
      "Epoch 6/10\n",
      "7943/7943 [==============================] - 2s 266us/step - loss: 0.5595 - acc: 0.7215\n",
      "Epoch 7/10\n",
      "7943/7943 [==============================] - 2s 269us/step - loss: 0.5630 - acc: 0.7220\n",
      "Epoch 8/10\n",
      "7943/7943 [==============================] - 2s 273us/step - loss: 0.5822 - acc: 0.7119\n",
      "Epoch 9/10\n",
      "7943/7943 [==============================] - 2s 266us/step - loss: 0.5622 - acc: 0.7240\n",
      "Epoch 10/10\n",
      "7943/7943 [==============================] - 2s 292us/step - loss: 0.5626 - acc: 0.7229\n",
      "0.7831401143576562\n"
     ]
    }
   ],
   "source": [
    "# same size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(32, (len(histones), 20), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 10), padding='valid'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(300))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(Dense(180))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=10)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "history.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5556965237249429\n",
      "0.8918040979510244\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_train[y_train == 1])\n",
    "print((pred[:, 0] < pred[:, 1]).sum() / pred.shape[0])\n",
    "pred = model.predict(X_train[y_train == 0])\n",
    "print((pred[:, 0] > pred[:, 1]).sum() / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 5, 100, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 91, 32)         1632      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 91, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2912)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                145650    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 180)               9180      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 362       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 156,824\n",
      "Trainable params: 156,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "0.79\n",
    "# -------------------------------------------------------------------\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(32, (len(histones), 10), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 10), padding='valid'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(300))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(Dense(180))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=5)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "history.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
