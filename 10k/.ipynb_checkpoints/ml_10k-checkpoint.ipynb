{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import Sequential\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def read_bed(filename):\n",
    "    return pd.read_csv(filename, sep='\\t', header=None)\n",
    "\n",
    "\n",
    "def to_bed(data, filename):\n",
    "    data.to_csv(filename, sep='\\t', header=None, index=None)\n",
    "\n",
    "N = 100\n",
    "chr_name = 'chr10'\n",
    "histones = ['E003-H3K4me1', 'E003-H3K4me3', 'E003-H3K9me3', 'E003-H3K27me3', 'E003-H3K36me3']\n",
    "h = histones[0]\n",
    "path_to_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>chr10</td>\n",
       "      <td>97755</td>\n",
       "      <td>107855</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chr10</td>\n",
       "      <td>97855</td>\n",
       "      <td>107955</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chr10</td>\n",
       "      <td>97955</td>\n",
       "      <td>108055</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>chr10</td>\n",
       "      <td>98055</td>\n",
       "      <td>108155</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chr10</td>\n",
       "      <td>98155</td>\n",
       "      <td>108255</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567395</td>\n",
       "      <td>chr10</td>\n",
       "      <td>135510970</td>\n",
       "      <td>135521070</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567396</td>\n",
       "      <td>chr10</td>\n",
       "      <td>135511070</td>\n",
       "      <td>135521170</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567397</td>\n",
       "      <td>chr10</td>\n",
       "      <td>135511170</td>\n",
       "      <td>135521270</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567398</td>\n",
       "      <td>chr10</td>\n",
       "      <td>135511270</td>\n",
       "      <td>135521370</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567399</td>\n",
       "      <td>chr10</td>\n",
       "      <td>135511370</td>\n",
       "      <td>135521470</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2   3\n",
       "0       chr10      97755     107855  27\n",
       "1       chr10      97855     107955  26\n",
       "2       chr10      97955     108055  26\n",
       "3       chr10      98055     108155  26\n",
       "4       chr10      98155     108255  26\n",
       "...       ...        ...        ...  ..\n",
       "567395  chr10  135510970  135521070  15\n",
       "567396  chr10  135511070  135521170  15\n",
       "567397  chr10  135511170  135521270  15\n",
       "567398  chr10  135511270  135521370  16\n",
       "567399  chr10  135511370  135521470  16\n",
       "\n",
       "[567400 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_bed('{}/plus_{}_{}_random_many.peaks'.format(chr_name, chr_name, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (11348, 5, 100)\n",
      "y: (11348,)\n"
     ]
    }
   ],
   "source": [
    "# regions_num = np.array(\n",
    "#     list(\n",
    "#         map(\n",
    "#             int,\n",
    "#             open(\n",
    "#                 '{}_regions_num.txt'.format(chr_name)\n",
    "#             ).read().strip().split()\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "regions_num = np.array([\n",
    "    read_bed('{}/plus_{}_{}.peaks'.format(chr_name, chr_name, h)).shape[0] // 100,\n",
    "    read_bed('{}/plus_{}_{}_random_many.peaks'.format(chr_name, chr_name, h)).shape[0] // 100\n",
    "])\n",
    "\n",
    "\n",
    "X_p = np.zeros((regions_num[0], len(histones), N))\n",
    "X_m = np.zeros((regions_num[1], len(histones), N))\n",
    "for i in range(len(histones)):\n",
    "    h = histones[i]\n",
    "    X_p[:, i, :] = np.array(read_bed('{}/plus_{}_{}.peaks'.format(chr_name, chr_name, h))[3]).reshape(regions_num[0], N)\n",
    "    X_m[:, i, :] = np.array(read_bed('{}/plus_{}_{}_random_many.peaks'.format(chr_name, chr_name, h))[3]).reshape(regions_num[1], N)\n",
    "\n",
    "X_p = X_p[np.random.choice(X_p.shape[0], X_m.shape[0]), :, :]\n",
    "X = np.concatenate([X_p, X_m])\n",
    "\n",
    "y = np.concatenate(\n",
    "    [\n",
    "        np.ones((X_p.shape[0])),\n",
    "        np.zeros((X_m.shape[0])),\n",
    "    ]\n",
    ")\n",
    "print('X:', X.shape)\n",
    "print('y:', y.shape)\n",
    "\n",
    "classes = 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_cat, y_test_cat = [keras.utils.to_categorical(y, classes) for y in [y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[119., 120., 119., ...,  50.,  49.,  45.],\n",
       "        [ 57.,  57.,  57., ...,  42.,  42.,  43.],\n",
       "        [132., 132., 132., ..., 139., 140., 141.],\n",
       "        [105., 105., 104., ...,  56.,  56.,  55.],\n",
       "        [ 88.,  88.,  88., ...,  67.,  67.,  64.]],\n",
       "\n",
       "       [[ 54.,  54.,  53., ...,  76.,  78.,  77.],\n",
       "        [ 41.,  41.,  41., ...,  49.,  47.,  46.],\n",
       "        [ 72.,  80.,  82., ...,  84.,  86.,  86.],\n",
       "        [ 65.,  67.,  67., ...,  77.,  78.,  77.],\n",
       "        [104., 106., 106., ..., 125., 125., 125.]],\n",
       "\n",
       "       [[ 72.,  71.,  72., ...,  87.,  85.,  81.],\n",
       "        [ 45.,  46.,  47., ...,  63.,  63.,  62.],\n",
       "        [ 72.,  72.,  74., ..., 121., 122., 121.],\n",
       "        [ 69.,  69.,  70., ..., 113., 113., 112.],\n",
       "        [ 59.,  59.,  60., ...,  82.,  81.,  79.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[122., 121., 117., ...,  90.,  90.,  90.],\n",
       "        [ 42.,  42.,  42., ...,  35.,  35.,  33.],\n",
       "        [133., 132., 132., ...,  90.,  87.,  85.],\n",
       "        [133., 133., 131., ...,  94.,  91.,  90.],\n",
       "        [ 83.,  83.,  83., ...,  58.,  59.,  59.]],\n",
       "\n",
       "       [[354., 359., 366., ..., 347., 337., 322.],\n",
       "        [ 87.,  88.,  89., ...,  77.,  73.,  70.],\n",
       "        [101., 101., 101., ..., 114., 115., 114.],\n",
       "        [174., 176., 180., ..., 139., 132., 132.],\n",
       "        [116., 116., 117., ..., 105., 105., 103.]],\n",
       "\n",
       "       [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   0.,   0.,   0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7943/7943 [==============================] - 2s 285us/step - loss: 12.3129 - acc: 0.5971\n",
      "Epoch 2/10\n",
      "7943/7943 [==============================] - 1s 133us/step - loss: 3.0791 - acc: 0.6195\n",
      "Epoch 3/10\n",
      "7943/7943 [==============================] - 1s 129us/step - loss: 1.8858 - acc: 0.6059\n",
      "Epoch 4/10\n",
      "7943/7943 [==============================] - 1s 130us/step - loss: 1.2716 - acc: 0.6198\n",
      "Epoch 5/10\n",
      "7943/7943 [==============================] - 1s 130us/step - loss: 0.8826 - acc: 0.6365\n",
      "Epoch 6/10\n",
      "7943/7943 [==============================] - 1s 142us/step - loss: 0.7771 - acc: 0.6535 0s - loss: 0.\n",
      "Epoch 7/10\n",
      "7943/7943 [==============================] - 2s 205us/step - loss: 0.7033 - acc: 0.6748\n",
      "Epoch 8/10\n",
      "7943/7943 [==============================] - 1s 140us/step - loss: 0.7344 - acc: 0.6806\n",
      "Epoch 9/10\n",
      "7943/7943 [==============================] - 1s 151us/step - loss: 0.7224 - acc: 0.6725\n",
      "Epoch 10/10\n",
      "7943/7943 [==============================] - 1s 144us/step - loss: 0.7984 - acc: 0.6622\n",
      "0.7551584496834596\n"
     ]
    }
   ],
   "source": [
    "# 10k, different size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=10)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5798020806901801\n",
      "0.7938530734632684\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_train[y_train == 1])\n",
    "print((pred[:, 0] < pred[:, 1]).sum() / pred.shape[0])\n",
    "pred = model.predict(X_train[y_train == 0])\n",
    "print((pred[:, 0] > pred[:, 1]).sum() / pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN different size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13127/13127 [==============================] - 14s 1ms/step - loss: 0.3854 - acc: 0.9007\n",
      "Epoch 2/5\n",
      "13127/13127 [==============================] - 15s 1ms/step - loss: 0.2829 - acc: 0.9057\n",
      "Epoch 3/5\n",
      "13127/13127 [==============================] - 16s 1ms/step - loss: 0.2790 - acc: 0.9058\n",
      "Epoch 4/5\n",
      "13127/13127 [==============================] - 18s 1ms/step - loss: 0.2800 - acc: 0.9055\n",
      "Epoch 5/5\n",
      "13127/13127 [==============================] - 16s 1ms/step - loss: 0.2750 - acc: 0.9058\n",
      "0.7828419922984661\n"
     ]
    }
   ],
   "source": [
    "# 10k, different size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(64, (len(histones), 10), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 10), padding='valid'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(300))\n",
    "# model.add(Activation(\"relu\"))\n",
    "model.add(Dense(180))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=5)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "# history.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7943/7943 [==============================] - 2s 299us/step - loss: 2.4021 - acc: 0.6218\n",
      "Epoch 2/10\n",
      "7943/7943 [==============================] - 1s 175us/step - loss: 0.7992 - acc: 0.6814\n",
      "Epoch 3/10\n",
      "7943/7943 [==============================] - 1s 177us/step - loss: 0.7051 - acc: 0.6981\n",
      "Epoch 4/10\n",
      "7943/7943 [==============================] - 1s 175us/step - loss: 0.6499 - acc: 0.6985\n",
      "Epoch 5/10\n",
      "7943/7943 [==============================] - 1s 176us/step - loss: 0.6212 - acc: 0.7009\n",
      "Epoch 6/10\n",
      "7943/7943 [==============================] - 1s 180us/step - loss: 0.6090 - acc: 0.7082\n",
      "Epoch 7/10\n",
      "7943/7943 [==============================] - 1s 180us/step - loss: 0.5703 - acc: 0.7205\n",
      "Epoch 8/10\n",
      "7943/7943 [==============================] - 2s 197us/step - loss: 0.5912 - acc: 0.6996\n",
      "Epoch 9/10\n",
      "7943/7943 [==============================] - 2s 198us/step - loss: 0.5624 - acc: 0.7135 0s - loss: 0.5682 - ac\n",
      "Epoch 10/10\n",
      "7943/7943 [==============================] - 1s 182us/step - loss: 0.5585 - acc: 0.7189\n",
      "0.7889551473369465\n"
     ]
    }
   ],
   "source": [
    "# 10k, same size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(16, (len(histones), 5), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# model.add(Conv2D(32, (1, 10), padding='valid'))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(70))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=10)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "# history.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7754590984974958\n",
      "0.652766639935846\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_train[y_train == 1])\n",
    "print((pred[:, 0] < pred[:, 1]).sum() / pred.shape[0])\n",
    "pred = model.predict(X_train[y_train == 0])\n",
    "print((pred[:, 0] > pred[:, 1]).sum() / pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7943/7943 [==============================] - 4s 441us/step - loss: 1.0210 - acc: 0.6403\n",
      "Epoch 2/10\n",
      "7943/7943 [==============================] - 2s 288us/step - loss: 0.6858 - acc: 0.6679\n",
      "Epoch 3/10\n",
      "7943/7943 [==============================] - 2s 292us/step - loss: 0.5682 - acc: 0.7192\n",
      "Epoch 4/10\n",
      "7943/7943 [==============================] - 2s 293us/step - loss: 0.5443 - acc: 0.7349\n",
      "Epoch 5/10\n",
      "7943/7943 [==============================] - 2s 305us/step - loss: 0.5305 - acc: 0.7344\n",
      "Epoch 6/10\n",
      "7943/7943 [==============================] - 2s 300us/step - loss: 0.5379 - acc: 0.7289\n",
      "Epoch 7/10\n",
      "7943/7943 [==============================] - 2s 280us/step - loss: 0.5244 - acc: 0.7383\n",
      "Epoch 8/10\n",
      "7943/7943 [==============================] - 2s 281us/step - loss: 0.5204 - acc: 0.7472\n",
      "Epoch 9/10\n",
      "7943/7943 [==============================] - 2s 281us/step - loss: 0.5122 - acc: 0.7452\n",
      "Epoch 10/10\n",
      "7943/7943 [==============================] - 2s 285us/step - loss: 0.5187 - acc: 0.7443\n",
      "0.8048051198657085\n"
     ]
    }
   ],
   "source": [
    "# 10k, same size\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Reshape, InputLayer, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((len(histones), N)))\n",
    "model.add(Reshape((len(histones), N, -1)))\n",
    "model.add(Conv2D(16, (len(histones), 5), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(16, (1, 5), padding='valid'))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(70))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(80))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train_cat, batch_size=64, epochs=10)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\n",
    "    roc_auc_score(y_test, model.predict(X_test)[:, 1])\n",
    ")\n",
    "# history.append((model, roc_auc_score(y_test, model.predict(X_test)[:, 1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
